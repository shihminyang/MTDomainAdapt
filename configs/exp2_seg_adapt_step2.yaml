exp_name: exp2_seg_adapt_step2  # Experiment name

# Logger options
resume: False                   # Wether resume training states
image_save_iter: 1000           # How often do you want to save output images during training
image_display_iter: 500         # How often do you want to display output images during training
snapshot_save_iter: 500         # How often do you want to save trained models
log_iter: 50                    # How often do you want to log the training stats
eval_iter: 500                  # How often do you want to evaluate the model in validation set

# Optimization options
max_epoch: 100                  # Maximum number of training epochs
max_iter: 1000000               # Maximum number of training iterations
cls_batch_size:                 # Batch size in training
seg_batch_size: 1               # Batch size in training
test_size: 1                    # Batch size in testing
momentum: 0.9
weight_decay: 0.0001            # Weight decay
lr: 0.0001                      # Initial learning rate
lr_policy: step                 # Learning rate scheduler [step/multi_step/constant]
step_size: 50000                # How often to decay learning rate
gamma: 0.5                      # How much to decay learning rate
init: kaiming                   # Initialization [gaussian/kaiming/xavier/orthogonal]

# Loss function weights
tran_dis_w: 0.05
tran_gen_w: 0.05
latent_dis_w: 0 #0.1
latent_gen_w: 0 #0.1
recon_w: 1                      # Weight of image reconstruction loss
cyc_w: 1                        # Weight of cycle consistency loss

cls_w: 0                        # Weight of classifier loss
seg_w: 1                        # Weight of segmentor loss
tran_cls_w: 0                   # Weight of translat classifier loss
tran_seg_w: 0.1                 # Weight of translate segmentor loss

# Model options
task: Segmentation              # [Classification/Segmentation/Multi_task]
trainer: SegmentAdapt
translator: Latent              # [None/Latent]
classifier:                     # [None/ResNet50/ResNet101]
segmentor: ResNet101            # [None/FCN8sRes50]
dis:
    dim: 16
    gan_type: lsgan             # [lsgan/nsgan]
    num_downsample: 4
dis_h:
    dim: 64
    gan_type: lsgan             # [lsgan/nsgan]
    num_downsample: 2
freeze_list:                    # ['gen_a_enc', 'segmentor', 'classifier', 'gen_b_enc', 'dis_h', 'enc_bridge']
    []

# Using pretrained model
pretrained_checkpoint:              # Directory for pretrained model.
    ./results/exp2_seg_adapt_step1/checkpoints
gen_weights: gen_00150000.pt
enc_weights:
dis_weights: dis_00150000.pt
bdg_weights: bdg_00150000.pt
cls_weights:
seg_weights: seg_00150000.pt

# Data options
num_class: {'cls': 12, 'seg': 20}   # Number of categories
num_workers: 6                      # Number of data loading threads.
new_size:                           # First resize the shortest image side to this size
    {'classification': ,
     'segmentation':   1024}
crop:                               # [Wether crop the images, crop height, crop width, wether pad after crop]
    {'classification': ,
     'segmentation':   [True, 512, 512]}

# Path and directory
data_root_cls:                      # Data root. Using for prepare dataset and data loader
    "./datasets/VisDA_17/closedset_classification"
data_root_seg:
    "./datasets/VisDA_17/semantic_segmentation"
data_list:
    {'train': 'train_list.txt', 'val': 'val_list.txt', 'test': 'test_list.txt'}

category:                           # Dataset category
    ['road', 'sidewalk', 'building', 'wall', 'fence',
     'pole', 'traffic light', 'traffic sign', 'vegetation', 'terrain',
     'sky', 'person', 'rider', 'car', 'truck',
     'bus', 'train', 'motorcycle', 'bicycle']

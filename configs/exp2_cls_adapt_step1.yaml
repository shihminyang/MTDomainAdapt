exp_name: exp2_cls_adapt_step1  # Experiment name


# Logger options
resume: False                   # Wether resume training states
image_save_iter: 2000           # How often do you want to save output images during training
image_display_iter: 1000        # How often do you want to display output images during training
snapshot_save_iter: 1000        # How often do you want to save trained models
log_iter: 100                   # How often do you want to log the training stats
eval_iter: 1000000              # How often do you want to evaluate the model in validation set

# Optimization options
max_epoch: 100                  # Maximum number of training epochs
max_iter: 1000000               # Maximum number of training iterations
cls_batch_size: 8               # Batch size in training
seg_batch_size:                 # Batch size in training
test_size: 1                    # Batch size in testing
momentum: 0.9
weight_decay: 0.0001            # Weight decay
lr: 0.0001                      # Initial learning rate
lr_policy: step                 # Learning rate scheduler [step/multi_step/constant]
step_size: 50000                # How often to decay learning rate
gamma: 0.5                      # How much to decay learning rate
init: kaiming                   # Initialization [gaussian/kaiming/xavier/orthogonal]

# Loss function weights
tran_dis_w: 0.1
tran_gen_w: 0.1
latent_dis_w: 0
latent_gen_w: 0
recon_w: 1                      # Weight of image reconstruction loss
cyc_w: 1                        # Weight of cycle consistency loss

cls_w: 0                        # Weight of classifier loss
seg_w: 0                        # Weight of segmentor loss
tran_cls_w: 0  # 0.1            # Weight of translat classifier loss
tran_seg_w: 0                   # Weight of translate segmentor loss

# Model options
task:       Classification      # [Classification/Segmentation/Multi_task]
trainer:    ClassifyAdapt
translator: Latent              # [None/Latent]
classifier: ResNet101           # [None/ResNet50/ResNet101]
segmentor:                      # [None/FCN8sRes50]
dis:
    dim: 16
    gan_type: lsgan             # [lsgan/nsgan]
    num_downsample: 4
dis_h:
    dim: 64
    gan_type: lsgan             # [lsgan/nsgan]
    num_downsample: 2
freeze_list:                    # ['gen_a_enc', 'segmentor', 'classifier', 'gen_b_enc', 'dis_h', 'enc_bridge']
    ['gen_a_enc', 'gen_b_enc', 'enc_bridge', 'classifier', 'dis_h']

# Using pretrained model
pretrained_checkpoint:              # Directory for pretrained model.
    ./results/exp1_cls_source_only/checkpoints
bdg_weights: bdg_00144000.pt
enc_weights: enc_00144000.pt
gen_weights:
cls_weights: cls_00144000.pt
seg_weights:
dis_weights:

# Data options
num_class: {'cls': 12, 'seg': 20}   # Number of categories
num_workers: 6                      # Number of data loading threads.
new_size:                           # First resize the shortest image side to this size
    {'classification': 256,
     'segmentation':   }
crop:                               # [Wether crop the images, crop height, crop width, wether pad after crop]
    {'classification': [True, 224, 224],
     'segmentation':   }

# Path and directory
data_root_cls:                      # Data root. Using for prepare dataset and data loader
    "./datasets/VisDA_17/closedset_classification"
data_root_seg:
    "./datasets/VisDA_17/semantic_segmentation"
data_list_s:
    {'train': 'source_train_list.txt', 'val': 'source_val_list.txt', 'test': 'source_test_list.txt'}
data_list_t:
    {'train': 'target_train_list.txt', 'val': 'target_val_list.txt', 'test': 'target_test_list.txt'}

category:                           # Dataset category
    ['aeroplane', 'bicycle', 'bus','car',
     'horse', 'knife', 'motorcycle', 'person',
     'plant', 'skateboard', 'train', 'truck']
